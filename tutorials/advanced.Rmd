---
title: "advanced_methods"
author: "Nathan Fox"
date: "30/03/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Now lets look at some more advanced methods - if you havent been able to follow along, we can create a break out room with one of us to help you go back over the basics, so please let us know!

## Computer vision

PLease note that these methods require a new API key 

## Text sentiment

Textual sentiment analysis assess the emotion expressed within a piece of text. This can be a powerful tool in understanding how people feel about the natural environment. As with previous task we need to download and  library the necersarry packages to perform these analysis.

```{r}
library(pacman)
p_load("tidytext",
       "textdata",
       "dplyr")
```

The most basic textual sentiment analysis is performed by comparing words to a pre-defined dictionary. These dictionaries have been created by other researchers who manually attributed a value to the sentiment of individual word. Today we will look at three dictionaries AFINN, bing and ncr. 

First, the AFINN dictionary [(Nielsen 2011)](https://arxiv.org/abs/1103.2903) ranks words on a scale of -5 to +5. Words negatively ranked are those with a negative associated sentiment and those with a positive rank are associated with a positive sentiment. While the number represents the magnitude of sentiment (e.g., +5 is more positive than +3).

```{r}
get_sentiments("afinn")
```

Second, the bing dictionary [Liu et al. ](https://www.morganclaypool.com/doi/abs/10.2200/s00416ed1v01y201204hlt016?casa_token=zVb-dykzCngAAAAA:joawB4fnvH6TWALFJeKJS8HiQQ07g920cdnjogMvSesova-GyXExeT7wwFkW2C6XjppwyThDHA) ranks word in a binary fashion of either positive of negative.

```{r}
get_sentiments("bing")
```

Third, the ncr dictionary [Mohammad and Turney 2010,](https://arxiv.org/pdf/1308.6297.pdf) categories word into different emotions: positive, negative, anger, anticipation, disgust, fear, joy, sadness, surprise, and trust.

```{r}
get_sentiments("nrc")
```

You may have noticed, not only do these dictionaries have different methods of measuring sentiment, they also have a different number of categorized words. This makes each dictionary good for different purposes. It has been demonstrated that AFINN is a good dictionary for evaluating social media data, so lets focus on that for now. 

### AFINN and Flickr text

Lets get some Flickr data.

```{r}
p_load_gh("ropensci/photosearcher")

flickr_text <- photo_search(text = "mountain",
                            mindate_taken = "2022-01-01",
                            maxdate_taken = "2022-01-08")
```

Now lets mergre all the text associated with the post (title, tags and description) into a single column. As the Flickr data is messy and contains lots of missing data we first create our own unique function called `paste2()`. For now lets not worry about the details of this function, but by doing `paste2 <- function(){}` we are telling R to create a new function called `paste2()` that carries out any code in the `{}` on the data defined in the `()`. To create a new column we can just use the `$` followed by a name of a column that doesn't alread exist, and then tell R what to place in this column


```{r}
#function to paste without copying NAs
paste2 <- function(...,sep=", ") {
  L <- list(...)
  L <- lapply(L,function(x) {x[is.na(x)] <- ""; x})
  gsub(paste0("(^",sep,"|",sep,"$)"),"",
       gsub(paste0(sep,sep),sep,
            do.call(paste,c(L,list(sep=sep)))))
}

#here we create a new column called text and paste in all the other text from that row
flickr_text$text <- paste2(flickr_text$title, 
                           flickr_text$description, 
                           flickr_text$tags) 

#lets inspect
head(flickr_text$text)
```

Finally, we need to use the AFINN dictionary to assess the sentiment of each word in the new 'text' column. 


The easiest way to do this is separate each piece of text into the individual words on a new row. 

```{r}
#unnest words - one row per word
flickr_text <- flickr_text %>%
  unnest_tokens(word, text) #creates col called word which matches afinn dictionary

head(flickr_text$word)
```

Next we add the dictionary sentiment value as a new row next to it. As both our data and the AFINN dictionary have a column called 'word' we can match our words to the values in the dictionary. This is achieved through the  `inner_join(get_sentiments("afinn")`. We then need to sum all the values for each individual photograph back up.This is achieved by the following lines of code: `group_by(url_l) %>% summarise(sentiment = sum(value))`

In these parts of the code we are using `%>%` to tell R to remeber the first piece of data and apply the following functions to it in a step-by-step way. This is a bit complicated but all covered in a short amount of code, so please ask for clarification if needed!

```{r}
#df of sum sentiment per photo 
afinn <- flickr_text %>% #select our data
  inner_join(get_sentiments("afinn")) %>% #add the afinn values as a new column
  group_by(url_l) %>%
  summarise(sentiment = sum(value))

head(afinn)
```
